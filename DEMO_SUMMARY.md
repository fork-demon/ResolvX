# Golden Agent Framework - Demo Summary

## âœ… Current Working State

### Components Running:
1. **Ollama LLM** - `http://localhost:11434` with `llama3.2` model
2. **MCP Mock Gateway** - `http://localhost:8081` with 12 tools
3. **6 Agents Started**:
   - Triage Agent
   - Poller Agent (polls every 30 mins)
   - Memory Agent
   - Splunk Agent
   - NewRelic Agent  
   - Supervisor Agent
4. **LangFuse Tracing** - Capturing all spans (backend configured)
5. **Mock Tickets** - 5 real tickets in `data/mock_tickets/` with status="new"

### End-to-End Flow Verified:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP       â”‚  Returns 5 real tickets from data/mock_tickets/
â”‚  Gateway    â”‚  (ALERT-001 to ALERT-005)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POLLER    â”‚  âœ“ Polls 20 tickets (5 per queue Ã— 4 queues)
â”‚   AGENT     â”‚  âœ“ Forwards tickets to Triage
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  âœ“ Trace: tickets_forwarded=20
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRIAGE    â”‚  1. Loads glossary (GTIN, TPNB, LocationCluster)
â”‚   AGENT     â”‚  2. Extracts entities from ticket
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  3. Maps entities â†’ candidate tools
       â”‚          4. Searches KB runbooks via RAG
       â”‚          5. Calls LLM (Ollama llama3.2) for plan
       â”‚          6. Executes tools based on plan
       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  GLOSSARY     â”‚  Entity extraction rules:
   â”‚  (YAML)       â”‚  - GTIN: \d{13,14}
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - TPNB: \d{8}
                      - LocationCluster: synonyms â†’ UUID
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  KB RUNBOOKS  â”‚  RAG search results:
   â”‚  (Markdown)    â”‚  - basket_segments_runbook.md
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - price_discrepancy_runbook.md
                      Tools suggested based on issue type
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  LLM PLANNER  â”‚  Ollama llama3.2 creates plan:
   â”‚  (Ollama)     â”‚  {
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    "analysis": "...",
                        "tools_to_call": ["splunk_search", "base_prices_get"],
                        "parameters": {...}
                      }
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  TOOL         â”‚  Executes via MCP:
   â”‚  EXECUTOR     â”‚  - splunk_search
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - newrelic_metrics
       â”‚              - base_prices_get
       â”‚              - basket_segment_get
       â–¼              - competitor_prices_get
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MEMORY     â”‚  âœ“ Searches historical tickets
â”‚  AGENT      â”‚  âœ“ Stores new tickets
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  âœ“ Returns related tickets if duplicates
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUPERVISOR  â”‚  Final decision:
â”‚  AGENT      â”‚  - COMMENT_AND_ASSIGN (with enriched data)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - ESCALATE_TO_HUMAN (if tools failed)
                 - REQUEST_MORE_INFO (if inconclusive)
```

## ğŸ¯ Demo Script: `scripts/demo_end_to_end.py`

Shows complete flow:
- Poller gets tickets from MCP
- For each ticket:
  1. **Entity Extraction** using glossary
  2. **Tool Mapping** based on entities
  3. **KB Search** using RAG (vector similarity on runbooks)
  4. **LLM Planning** with Ollama llama3.2
  5. **Tool Execution** via MCP (Splunk/NewRelic/Price APIs)
  6. **Supervisor Decision** with enriched context

## ğŸ” Example Ticket Processing

### Ticket: ALERT-001 - "Basket segments - File drop process failed"

1. **Entities Extracted:**
   - Source: Splunk
   - Environment: PPE
   - Tags: basket-segments, file-drop, timeout

2. **Tool Mapping:**
   - From glossary rules â†’ `basket_segment_get`, `splunk_search`

3. **KB Search:**
   - Score 0.85: `basket_segments_runbook.md`
   - Runbook suggests: Check Splunk â†’ Verify file â†’ Check New Relic

4. **LLM Plan (llama3.2):**
   ```json
   {
     "analysis": "File drop timeout, likely SharePoint connectivity issue",
     "tools_to_call": ["splunk_search", "newrelic_metrics", "basket_segment_get"],
     "parameters": {
       "splunk_search": {"query": "index=price-advisory CreateBasketSegmentsProcessor timeout"},
       "newrelic_metrics": {"nrql": "SELECT average(duration) FROM Transaction..."},
       "basket_segment_get": {"tpnb": "<from_ticket>", "locationClusterId": "<from_glossary>"}
     },
     "expected_outcome": "Identify if timeout is transient or systemic"
   }
   ```

5. **Tools Executed:**
   - âœ“ `splunk_search` â†’ Returns log entries
   - âœ“ `newrelic_metrics` â†’ Returns performance data
   - âœ“ `basket_segment_get` â†’ Returns current segment data

6. **Supervisor Decision:**
   - Decision: `COMMENT_AND_ASSIGN`
   - Reason: "Diagnostic data collected, assign to pricing team"
   - Comment: Includes Splunk logs + NR metrics + current state

## ğŸ“Š Observability

All traces captured in LangFuse:
- Span: `zendesk_poller_process` (tickets_forwarded=20)
- Span: `memory_agent_process` (ticket_id=ALERT-001, related_count=0)
- Span: `mcp_tool_poll_queue` (gateway calls)
- Span: `llm_chat_completion` (Ollama llama3.2 reasoning)

View at: `http://localhost:3000` (once Langfuse is accessible)

## ğŸš€ Quick Test Commands

```bash
# 1. Smoke test (components only)
python scripts/smoke_test.py

# 2. Full end-to-end demo (with LLM reasoning)
python scripts/demo_end_to_end.py

# 3. Start all agents (runs continuously)
python scripts/start_agents.py

# 4. Quick verification (exits after 10s)
START_AGENTS_VERIFY_SECONDS=10 START_AGENTS_EXIT_AFTER_VERIFY=1 python scripts/start_agents.py
```

## ğŸ“ Configuration

- **LLM**: Ollama llama3.2 at `http://localhost:11434`
- **MCP**: Mock gateway at `http://localhost:8081`
- **Tracing**: LangFuse at `http://localhost:3000`
- **KB**: 3 markdown runbooks in `kb/`
- **Glossary**: Entity definitions in `resources/triage/glossary.yaml`
- **Mock Tickets**: 5 JSON files in `data/mock_tickets/`

## ğŸ“ Key Design Patterns

1. **Glossary-Driven Entity Extraction** - Business domain understanding
2. **RAG for Runbook Selection** - Vector search over KB articles
3. **LLM for Planning** - Ollama creates tool execution plan
4. **MCP for Tool Execution** - Centralized gateway routing
5. **Memory for Deduplication** - Historical ticket search
6. **Supervisor for Final Decision** - Enriched context â†’ action

