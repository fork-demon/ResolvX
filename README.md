# TescoResolveX

**AI-Powered Support Automation Framework** - Multi-agent system for intelligent ticket triage, routing, and resolution with full observability.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Technical Components](#technical-components)
- [Agentic Pattern](#agentic-pattern)
- [Installation](#installation)
- [Configuration](#configuration)
- [Running the System](#running-the-system)
- [Project Structure](#project-structure)
- [Observability](#observability)
- [Development](#development)
- [Testing](#testing)

---

## ğŸ¯ Overview

**TescoResolveX** is an enterprise-grade AI agent framework designed to automate support operations by intelligently analyzing, routing, and resolving incidents. The system uses a **multi-agent architecture** powered by Large Language Models (LLMs) with built-in observability, tool orchestration, and knowledge base integration.

### What This Template Does

1. **Polls Support Tickets** from Zendesk queues on a schedule
2. **Detects Duplicates** using FAISS vector memory (similarity search)
3. **Analyzes Incidents** using Chain-of-Thought reasoning with LLMs
4. **Executes Diagnostic Tools** via MCP (Model Context Protocol) gateways
5. **Retrieves Knowledge Base** articles using RAG (Retrieval-Augmented Generation)
6. **Makes Routing Decisions** with a Supervisor agent
7. **Executes Actions** (add comments, assign teams, escalate) via Executor agent
8. **Traces Everything** in LangFuse for debugging and monitoring

---

## âœ¨ Key Features

### ğŸ¤– Multi-Agent System
- **5 Specialized Agents**: Poller â†’ Memory â†’ Triage â†’ Supervisor â†’ Executor
- **LangGraph-based** state machines with retry logic and error handling
- **Clear separation of concerns**: Analysis vs. Execution

### ğŸ§  Chain-of-Thought (CoT) Reasoning
- **Step 1**: Entity extraction (GTIN, TPNB, incident type, key terms)
- **Step 2**: RAG knowledge base search for relevant runbooks
- **Step 3**: Execution plan creation with tool selection
- **Step 4**: Automatic parameter mapping (schema-driven, no hallucination)
- **Step 5**: Tool execution via MCP gateways
- **Step 6**: Synthesis - actionable summary with root cause analysis

### ğŸ”§ Tool Orchestration
- **MCP Protocol** for microservice tool discovery
- **Dynamic tool registry** - no hardcoding required
- **Automatic parameter mapping** using JSON schemas
- **13+ tools** including Splunk, Price APIs, SharePoint, NewRelic

### ğŸ“š Knowledge Base (RAG)
- **FAISS-powered** vector search for fast KB retrieval
- **Markdown runbooks** indexed automatically from `kb/` folder
- **Relevance scoring** to fetch the most appropriate guidance

### ğŸ” Full Observability
- **LangFuse integration** - trace every agent, LLM call, and tool execution
- **Nested span tracking** - see the complete call hierarchy
- **Input/output logging** - debug with full context
- **Performance metrics** - latency, token usage, success rates

### ğŸ›¡ï¸ Production-Ready
- **Circuit breakers** for external service failures
- **Retry logic** with exponential backoff
- **Health checks** for all components
- **Async/await** architecture for high concurrency
- **Configurable timeouts** and resource limits

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          WORKFLOW ORCHESTRATOR                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                               â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  POLLER AGENT     â”‚         â”‚  MEMORY AGENT     â”‚
          â”‚  (Zendesk)        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (FAISS Vector)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                    Duplicate? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ No
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       TRIAGE AGENT (CoT)             â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚ 1. Entity Extraction (LLM)      â”‚ â”‚
                    â”‚  â”‚ 2. RAG KB Search (FAISS)        â”‚ â”‚
                    â”‚  â”‚ 3. Plan Creation (LLM)          â”‚ â”‚
                    â”‚  â”‚ 4. Parameter Mapping (Schema)   â”‚ â”‚
                    â”‚  â”‚ 5. Tool Execution (MCP)         â”‚ â”‚
                    â”‚  â”‚ 6. Synthesis (LLM)              â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Analysis + Synthesis
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    SUPERVISOR AGENT                  â”‚
                    â”‚  - Reviews synthesis                 â”‚
                    â”‚  - Makes routing decision            â”‚
                    â”‚  - Determines escalation             â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Decision
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    EXECUTOR AGENT                    â”‚
                    â”‚  - Add comments                      â”‚
                    â”‚  - Assign to teams                   â”‚
                    â”‚  - Escalate to humans                â”‚
                    â”‚  - Update ticket status              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚                     â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                    â”‚ Zendesk â”‚          â”‚LangFuse â”‚
                    â”‚   API   â”‚          â”‚ Traces  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Responsibilities

| Agent | Type | Purpose | Key Actions |
|-------|------|---------|-------------|
| **Poller** | Data Ingestion | Monitor Zendesk queues | Poll tickets, filter by priority |
| **Memory** | Deduplication | Prevent duplicate processing | FAISS similarity search, flag duplicates |
| **Triage** | Analysis | CoT reasoning + tool execution | Entity extraction, RAG search, plan execution, synthesis |
| **Supervisor** | Decision | Final routing and escalation | Review synthesis, assign teams, escalate |
| **Executor** | Action | Modify tickets in Zendesk | Add comments, assign, escalate, tag |

---

## ğŸ”§ Technical Components

### 1. **Core Framework** (`core/`)
- **`config.py`**: YAML-based configuration with env variable substitution
- **`gateway/`**: LLM client, MCP client, tool registry, parameter mapper
- **`memory/`**: FAISS vector store, Redis adapter (optional)
- **`observability/`**: LangFuse, LangSmith, console tracers
- **`graph/`**: LangGraph base agent, state management
- **`rag/`**: FAISS-based knowledge base indexing and search

### 2. **Agents** (`agents/`)
- **`poller/`**: Zendesk ticket polling with queue management
- **`memory/`**: Duplicate detection using vector similarity
- **`triage/`**: Main analysis agent with 6-step CoT reasoning
- **`supervisor/`**: Decision-making agent for routing/escalation
- **`executor/`**: Action execution agent with retry logic

### 3. **MCP Gateways** (`mcp_gateway/`)
- **Engineering tools**: Splunk, NewRelic, Prometheus
- **Pricing tools**: Price Advisory APIs (base prices, competitor prices, basket segments)
- **SharePoint tools**: Document search, file listing, downloads
- **Auto-discovery**: Gateways expose tool schemas via MCP protocol

### 4. **Knowledge Base** (`kb/`)
- Markdown files for runbooks and troubleshooting guides
- Automatically indexed by FAISS on startup
- Queried via semantic search during triage

### 5. **Configuration** (`config/`)
- **`agent.yaml`**: Main configuration for all agents, tools, and observability
- Supports environment variable substitution: `{VAR_NAME}`

---

## ğŸ­ Agentic Pattern

### Multi-Agent Workflow Pattern
TescoResolveX implements the **Supervisor Pattern** with specialized agents:

1. **Orchestration Layer**: `WorkflowOrchestrator` coordinates agent execution
2. **Agent Layer**: Each agent is a LangGraph state machine with defined transitions
3. **Tool Layer**: MCP gateways provide discoverable tools
4. **Observability Layer**: LangFuse captures all agent interactions

### Chain-of-Thought (CoT) Pattern
The Triage agent uses **multi-step reasoning** inspired by Claude/ChatGPT:

```python
# Step 1: Extract structured entities
entities = llm.extract({
    "gtin": "14-digit product code",
    "tpnb": "9-digit product code",
    "incident_type": "classification",
    "key_terms": ["relevant", "keywords"]
})

# Step 2: Retrieve relevant knowledge
kb_articles = rag.search(entities["key_terms"], k=1)

# Step 3: Create execution plan
plan = llm.create_plan({
    "incident_type": entities["incident_type"],
    "kb_guidance": kb_articles,
    "available_tools": tool_registry.list()
})

# Step 4: Map parameters automatically (deterministic)
payloads = parameter_mapper.map(plan["steps"], entities)

# Step 5: Execute tools
results = await execute_tools(plan["steps"], payloads)

# Step 6: Synthesize findings
synthesis = llm.synthesize({
    "ticket": ticket,
    "entities": entities,
    "tool_results": results,
    "kb_guidance": kb_articles
})
```

### Why This Pattern?

âœ… **Prevents hallucination**: Schema-driven parameter mapping (Step 4)  
âœ… **Leverages domain knowledge**: RAG retrieves runbooks (Step 2)  
âœ… **Explainable**: Each step is traced independently  
âœ… **Maintainable**: Adding tools doesn't require prompt changes  
âœ… **Scalable**: Agents can run independently or in parallel  

---

## ğŸš€ Installation

See **[QUICK_INSTALL.md](QUICK_INSTALL.md)** for detailed setup instructions.

### Quick Start

```bash
# 1. Clone repository
git clone <repo-url>
cd TescoResolveX

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up environment variables
cp .env.example .env
# Edit .env with your credentials

# 4. Start Ollama (LLM)
ollama serve

# 5. Start LangFuse (Observability)
cd langfuse && docker-compose up -d

# 6. Initialize knowledge base
python scripts/index_kb.py

# 7. Run full workflow test
python scripts/test_full_workflow.py
```

---

## âš™ï¸ Configuration

### Environment Variables (`.env`)

```bash
# LLM Gateway
CENTRAL_LLM_GATEWAY_URL=http://localhost:11434

# Observability
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=http://localhost:3000

# Zendesk
ZENDESK_SUBDOMAIN=yourcompany
ZENDESK_SERVICE_EMAIL=support@yourcompany.com
ZENDESK_API_TOKEN=your_token

# MCP Gateways
MCP_ENGINEERING_URL=http://localhost:3001
MCP_PRICING_URL=http://localhost:3002
```

### Agent Configuration (`config/agent.yaml`)

```yaml
agents:
  triage:
    enabled: true
    model: "llama3.2"
    team: "operations"
    
  supervisor:
    enabled: true
    team: "operations"
    
  executor:
    enabled: true
    max_retries: 3
    retry_delay: 2.0
    team_mappings:
      engineering_team: "team_eng_001"
      pricing_team: "team_pricing_001"
```

---

## ğŸƒ Running the System

### 1. Start Infrastructure

```bash
# Terminal 1: Ollama LLM
ollama serve

# Terminal 2: LangFuse
cd langfuse && docker-compose up

# Terminal 3: MCP Gateways (optional for testing)
cd mcp_gateway && python engineering_gateway.py
```

### 2. Run Test Workflow

```bash
# Full end-to-end test (Poller â†’ Memory â†’ Triage â†’ Supervisor â†’ Executor)
python scripts/test_full_workflow.py

# View traces in LangFuse
open http://localhost:3000
```

### 3. Run Production Agents

```bash
# Start all agents
python scripts/start_agents.py

# Or run individual agents
python -m agents.poller.agent    # Polls tickets every 30 min
python -m agents.triage.agent    # Processes from queue
python -m agents.supervisor.agent
```

---

## ğŸ“ Project Structure

```
TescoResolveX/
â”œâ”€â”€ agents/                      # Agent implementations (LangGraph)
â”‚   â”œâ”€â”€ poller/                  # Zendesk ticket polling
â”‚   â”œâ”€â”€ memory/                  # FAISS duplicate detection
â”‚   â”œâ”€â”€ triage/                  # CoT analysis + tool execution
â”‚   â”œâ”€â”€ supervisor/              # Final decision maker
â”‚   â””â”€â”€ executor/                # Action executor (Zendesk API)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config/                  # Configuration management
â”‚   â”œâ”€â”€ gateway/
â”‚   â”‚   â”œâ”€â”€ tool_registry.py     # Multi-gateway tool registry
â”‚   â”‚   â”œâ”€â”€ mcp_client.py        # MCP protocol client
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # Ollama LLM client
â”‚   â”‚   â””â”€â”€ parameter_mapper.py  # Schema-driven parameter mapping
â”‚   â”œâ”€â”€ memory/                  # FAISS vector memory
â”‚   â”œâ”€â”€ observability/           # LangFuse, LangSmith tracers
â”‚   â”œâ”€â”€ rag/                     # FAISS KB indexing and search
â”‚   â””â”€â”€ graph/                   # LangGraph base agent
â”œâ”€â”€ mcp_gateway/                 # MCP tool gateways
â”‚   â”œâ”€â”€ engineering_gateway.py   # Splunk, NewRelic tools
â”‚   â”œâ”€â”€ pricing_gateway.py       # Price Advisory APIs
â”‚   â””â”€â”€ sharepoint_gateway.py    # SharePoint tools
â”œâ”€â”€ kb/                          # Knowledge base (runbooks)
â”‚   â”œâ”€â”€ basket_segments_runbook.md
â”‚   â”œâ”€â”€ price_missing_runbook.md
â”‚   â””â”€â”€ file_drop_runbook.md
â”œâ”€â”€ prompts/                     # LLM prompts for agents
â”‚   â”œâ”€â”€ triage/
â”‚   â”‚   â”œâ”€â”€ step1_entity_extraction.md
â”‚   â”‚   â”œâ”€â”€ step2_create_plan.md
â”‚   â”‚   â””â”€â”€ step3_synthesize_results.md
â”‚   â””â”€â”€ executor/
â”‚       â””â”€â”€ comment_templates.md
â”œâ”€â”€ config/
â”‚   â””â”€â”€ agent.yaml               # Main configuration
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_full_workflow.py    # End-to-end test
â”‚   â”œâ”€â”€ start_agents.py          # Production agent launcher
â”‚   â””â”€â”€ index_kb.py              # Index knowledge base
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ faiss_index/             # FAISS memory indices
â”‚   â”œâ”€â”€ faiss_kb_index/          # FAISS KB indices
â”‚   â””â”€â”€ mock_tickets/            # Test data
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # This file
â””â”€â”€ QUICK_INSTALL.md             # Installation guide
```

---

## ğŸ” Observability

### LangFuse Dashboard

All agent executions are traced in **LangFuse** with full observability:

1. **Traces View**: See all workflow executions
2. **Agent Spans**: Nested spans for each agent
3. **LLM Calls**: Token usage, latency, input/output
4. **Tool Executions**: Which tools ran and their results
5. **Error Tracking**: Failed steps with stack traces

**Example Trace Hierarchy**:
```
workflow_execution (15.2s)
â”œâ”€â”€ zendesk_poller_process (0.5s)
â”œâ”€â”€ memory_agent_process (1.2s)
â”œâ”€â”€ triage_process (9.7s)
â”‚   â”œâ”€â”€ rag_knowledge_search (0.2s)
â”‚   â”œâ”€â”€ cot_entity_extraction (2.6s)
â”‚   â”‚   â””â”€â”€ llm_chat_completion (2.5s)
â”‚   â”œâ”€â”€ cot_plan_creation (6.1s)
â”‚   â”‚   â””â”€â”€ llm_chat_completion (6.0s)
â”‚   â”œâ”€â”€ mcp_tool_splunk_search (0.3s)
â”‚   â”œâ”€â”€ mcp_tool_base_prices_get (0.2s)
â”‚   â”œâ”€â”€ mcp_tool_sharepoint_list_files (0.1s)
â”‚   â””â”€â”€ cot_synthesis (3.2s)
â”‚       â””â”€â”€ llm_chat_completion (3.1s)
â”œâ”€â”€ supervisor_process (0.5s)
â””â”€â”€ executor_process (1.3s)
    â”œâ”€â”€ _execute_action (0.8s)
    â”œâ”€â”€ _validate_execution (0.3s)
    â””â”€â”€ _should_retry (0.2s)
```

Access: **http://localhost:3000**

---

## ğŸ§ª Testing

### Run Full Workflow Test

```bash
python scripts/test_full_workflow.py
```

This will:
1. Poll mock tickets from `data/mock_tickets/`
2. Check for duplicates in vector memory
3. Run CoT analysis with tool execution
4. Make supervisor decision
5. Execute actions via executor
6. Send traces to LangFuse

### Check LangFuse

Open http://localhost:3000 and search for traces. You should see:
- `zendesk_poller_process`
- `memory_agent_process`
- `triage_process` (with nested CoT spans)
- `supervisor_process`
- `executor_process`

---

## ğŸ› ï¸ Development

### Adding a New Tool

1. **Add tool to MCP gateway** (e.g., `mcp_gateway/engineering_gateway.py`):
```python
@app.post("/execute")
async def execute_tool(request: ToolRequest):
    if request.tool == "my_new_tool":
        return {"success": True, "data": ...}
```

2. **Add JSON schema**:
```python
TOOL_SCHEMAS["my_new_tool"] = {
    "name": "my_new_tool",
    "description": "What it does",
    "parameters": {
        "param1": {"type": "string", "required": True},
        "param2": {"type": "number", "required": False}
    }
}
```

3. **Update KB runbooks** to reference the tool:
```markdown
## Troubleshooting Steps
1. Check logs: Use `my_new_tool` with param1=...
```

That's it! The tool will automatically:
- Be discovered by the tool registry
- Appear in plan creation prompts
- Have parameters mapped automatically

### Adding a New Runbook

1. Create markdown file in `kb/`:
```bash
echo "# New Issue Type\n## Symptoms\n## Root Causes\n## Steps" > kb/new_issue.md
```

2. Re-index knowledge base:
```bash
python scripts/index_kb.py
```

The runbook will be searchable via RAG during triage.

---

## ğŸ“Š Key Metrics

Track these in LangFuse or logs:

- **Ticket Processing Time**: End-to-end latency per ticket
- **Tool Success Rate**: % of successful tool executions
- **LLM Token Usage**: Total tokens per analysis
- **Escalation Rate**: % of tickets escalated to humans
- **Duplicate Detection Rate**: % of duplicates caught
- **Agent Retry Rate**: How often executors retry

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Make changes and test: `python scripts/test_full_workflow.py`
4. Commit: `git commit -am 'Add my feature'`
5. Push: `git push origin feature/my-feature`
6. Create Pull Request

---

## ğŸ“ License

[Your License Here]

---

## ğŸ™‹ Support

For issues or questions:
- Check **LangFuse traces** first: http://localhost:3000
- Review agent logs in console output
- Open an issue on GitHub

---

## ğŸ¯ Roadmap

- [ ] Add support for Slack notifications
- [ ] Implement auto-resolution for common issues
- [ ] Add batch processing for high ticket volumes
- [ ] Integrate with Jira for advanced workflows
- [ ] Build self-healing capabilities (auto-retry failed actions)

---

**Built with â¤ï¸ for intelligent support automation**
